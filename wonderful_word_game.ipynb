{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768935f4",
   "metadata": {},
   "source": [
    "# 유사한 단어 찾기 게임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f89bb1",
   "metadata": {},
   "source": [
    "1. 사전 학습된 모델 또는 적잘한 데이터셋을 찾는다\n",
    "2. 워드 임베딩 모델을 학습 시킨다\n",
    "3. 단어 유사도가 0.8 이상인 A, B를 랜덤 추출한다\n",
    "4. A, B와 대응되는 C를 추출한다\n",
    "5. D를 입력 받는다.\n",
    "\n",
    "=>  \n",
    "A:B = C:D 관계에 대응하는 D를 찾는 게임을 만든다.   \n",
    "ex) A: 산, B: 바다, C: 나무, D: 물"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657c26b",
   "metadata": {},
   "source": [
    "**<출력 예시>**\n",
    "\n",
    "관계 [수긍:추락 = 대사관:?]<br>\n",
    "모델이 예측한 가장 적합한 단어: 잠입<br>\n",
    "당신의 답변과 모델 예측의 유사도: 0.34<br>\n",
    "아쉽네요. 더 생각해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import fasttext\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def load_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        stopwords = [line.strip() for line in f]\n",
    "    return stopwords\n",
    "\n",
    "ko_stopwords = load_stopwords('ko_stopwords.txt')\n",
    "\n",
    "def preprocess(text, return_tokens=False):\n",
    "    text = re.sub(\"[^가-힣 ]\", \"\", text)\n",
    "    tokens = okt.morphs(text, stem=True)\n",
    "    tokens = [word for word in tokens if word not in ko_stopwords]\n",
    "    return tokens if return_tokens else ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8669e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_txt = []\n",
    "with open(\"naver_movie_ratings.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    next(f)  # 첫 줄(header) 건너뛰기\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) == 3:  # id, document, label\n",
    "            _, document, _ = parts\n",
    "            if document.strip():  # 비어있는 리뷰 제거\n",
    "                load_txt.append(preprocess(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f2d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in load_txt:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e51592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9952020645141602, '영화인'), (0.9945622682571411, '영화관'), (0.9941626787185669, '명작'), (0.9940668940544128, '애니메이션'), (0.9939450621604919, '공포영화'), (0.9939148426055908, '이다'), (0.9938288331031799, '홍콩영화'), (0.9937629699707031, '엄청나다'), (0.993675172328949, '년전'), (0.9935327768325806, '평가')]\n"
     ]
    }
   ],
   "source": [
    "# skipgram 방식 (단어 임베딩 학습)\n",
    "model = fasttext.train_unsupervised(\n",
    "    'corpus.txt',\n",
    "    model='skipgram',\n",
    "    minCount=10,\n",
    "    dim=100,\n",
    "    minn=3,\n",
    "    maxn=5,\n",
    ")\n",
    "\n",
    "# 유사 단어 찾기 테스트\n",
    "print(model.get_nearest_neighbors(\"영화\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0b91526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def find_random_similar_pair(model, threshold=0.8, max_trials=1000):\n",
    "    words = model.get_words()\n",
    "    for _ in range(max_trials):\n",
    "        A = random.choice(words)\n",
    "        similar_words = model.get_nearest_neighbors(A, k=20)  # [(score, word)]\n",
    "        # threshold 이상인 단어 중 랜덤 선택\n",
    "        candidates = [w for score, w in similar_words if score >= threshold and w != A]\n",
    "        if candidates:\n",
    "            B = random.choice(candidates)\n",
    "            return A, B\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c77fc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_with_similarity(model, word_a, word_b, word_c, topn=5):\n",
    "    \"\"\"\n",
    "    A : B = C : D 관계에서 D를 찾는 함수와 유사도 계산\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 입력 단어가 모델에 있는지 확인\n",
    "        if not all(word in model.get_words() for word in [word_a, word_b, word_c]):\n",
    "            raise KeyError(\"입력 단어 중 하나가 모델에 없습니다.\")\n",
    "        \n",
    "        # A - B + C 벡터 계산\n",
    "        vector = model.get_word_vector(word_b) - model.get_word_vector(word_a) + model.get_word_vector(word_c)\n",
    "        \n",
    "        # 벡터 정규화\n",
    "        def normalize(v):\n",
    "            norm = np.linalg.norm(v)\n",
    "            return v / norm if norm > 0 else v\n",
    "        \n",
    "        vector = normalize(vector)\n",
    "        \n",
    "        # 모든 단어와의 유사도 계산\n",
    "        words = model.get_words()\n",
    "        similarities = [\n",
    "            (word, np.dot(normalize(vector), normalize(model.get_word_vector(word))))\n",
    "            for word in words\n",
    "        ]\n",
    "        \n",
    "        # 유사도 기준으로 정렬\n",
    "        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 입력 단어 제외\n",
    "        candidates = [(word, similarity) for word, similarity in similarities if word not in {word_a, word_b, word_c}]\n",
    "        \n",
    "        # 상위 topn 단어 반환\n",
    "        top_candidates = candidates[:topn]\n",
    "        \n",
    "        # A:B와 C:D 유사도 계산\n",
    "        a_b_similarity = np.dot(\n",
    "            normalize(model.get_word_vector(word_a)),\n",
    "            normalize(model.get_word_vector(word_b))\n",
    "        )\n",
    "        c_d_similarity = np.dot(\n",
    "            normalize(model.get_word_vector(word_c)),\n",
    "            normalize(model.get_word_vector(top_candidates[0][0]))\n",
    "        )\n",
    "        \n",
    "        return top_candidates, a_b_similarity, c_d_similarity\n",
    "    except KeyError as e:\n",
    "        print(f\"단어를 찾을 수 없습니다: {e}\")\n",
    "        return [], None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f8d9f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제: 공감 : 외로움 = 뒤 : ?\n",
      "정답 후보:\n",
      "  계 (유사도: 0.9944)\n",
      "  남녀 (유사도: 0.9944)\n",
      "  작다 (유사도: 0.9943)\n",
      "  외계인 (유사도: 0.9943)\n",
      "  갈수록 (유사도: 0.9943)\n",
      "\n",
      "유사도:\n",
      "  공감:외로움 유사도 = 0.9987\n",
      "  뒤:계 유사도 = 0.9945\n"
     ]
    }
   ],
   "source": [
    "A, B = find_random_similar_pair(model)\n",
    "C = random.choice(model.get_words())\n",
    "D_candidates, a_b_similarity, c_d_similarity = analogy_with_similarity(model, A, B, C, topn=5)\n",
    "\n",
    "print(f\"문제: {A} : {B} = {C} : ?\")\n",
    "if D_candidates:\n",
    "    print(\"정답 후보:\")\n",
    "    for word, similarity in D_candidates:\n",
    "        print(f\"  {word} (유사도: {similarity:.4f})\")\n",
    "    print(f\"\\n유사도:\")\n",
    "    print(f\"  {A}:{B} 유사도 = {a_b_similarity:.4f}\")\n",
    "    print(f\"  {C}:{D_candidates[0][0]} 유사도 = {c_d_similarity:.4f}\")\n",
    "else:\n",
    "    print(\"정답 후보를 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0eb1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
